{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec实现\n",
    "## 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import d2lzh as d2l\n",
    "import math\n",
    "from mxnet import autograd, gluon, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理\n",
    "### 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# books: 6'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rawdata(path):\n",
    "    filenames = os.listdir(path)\n",
    "    lines = []\n",
    "    raw_dataset = []\n",
    "    for filename in filenames:\n",
    "        filepath = path + filename\n",
    "        with open(filepath,'r') as f:\n",
    "            lines = f.readlines()\n",
    "            raw_dataset.append([st.split() for st in lines])\n",
    "    return raw_dataset\n",
    "raw_dataset = get_rawdata(\"../data/\")\n",
    "'# books: %d' % len(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# sentences: 4199703'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为是六本书，分开处理不太方便，又因为是一个系列的，所以融合成一起\n",
    "raw_dataset = [token for book in raw_dataset for st in book for token in st]\n",
    "'# sentences: %d' % len(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHAPTER', 'ONE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['man',\n",
       " 'with',\n",
       " 'hardly',\n",
       " 'any',\n",
       " 'neck,',\n",
       " 'although',\n",
       " 'he',\n",
       " 'did',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'large',\n",
       " 'mustache.',\n",
       " 'Mrs.',\n",
       " 'Dursley',\n",
       " 'was',\n",
       " 'thin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
